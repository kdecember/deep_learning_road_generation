{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code was acquired from [here](https://wiki.pathmind.com/generative-adversarial-network-gan#:~:text=Generative%20adversarial%20networks%20(GANs)%20are,video%20generation%20and%20voice%20generation.) for learning purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\kyled\\anaconda3\\envs\\ml_base:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_tflow_select             2.3.0                     eigen  \n",
      "absl-py                   0.11.0             pyhd3eb1b0_1  \n",
      "aiohttp                   3.7.3            py38h2bbff1b_1  \n",
      "astunparse                1.6.3                      py_0  \n",
      "async-timeout             3.0.1            py38haa95532_0  \n",
      "attrs                     20.3.0             pyhd3eb1b0_0  \n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "blas                      1.0                         mkl  \n",
      "blinker                   1.4              py38haa95532_0  \n",
      "brotlipy                  0.7.0           py38h2bbff1b_1003  \n",
      "ca-certificates           2021.1.19            haa95532_0  \n",
      "cachetools                4.2.1              pyhd3eb1b0_0  \n",
      "certifi                   2020.12.5        py38haa95532_0  \n",
      "cffi                      1.14.4           py38hcd4344a_0  \n",
      "chardet                   3.0.4           py38haa95532_1003  \n",
      "click                     7.1.2              pyhd3eb1b0_0  \n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \n",
      "cryptography              2.9.2            py38h7a1dbc1_0  \n",
      "cycler                    0.10.0                   py38_0  \n",
      "decorator                 4.4.2              pyhd3eb1b0_0  \n",
      "freetype                  2.10.4               hd328e21_0  \n",
      "gast                      0.4.0                      py_0  \n",
      "google-auth               1.24.0             pyhd3eb1b0_0  \n",
      "google-auth-oauthlib      0.4.2              pyhd3eb1b0_2  \n",
      "google-pasta              0.2.0                      py_0  \n",
      "grpcio                    1.31.0           py38he7da953_0  \n",
      "h5py                      2.10.0           py38h5e291fa_0  \n",
      "hdf5                      1.10.4               h7ebc959_0  \n",
      "icc_rt                    2019.0.0             h0cc432a_1  \n",
      "icu                       58.2                 ha925a31_3  \n",
      "idna                      2.10               pyhd3eb1b0_0  \n",
      "importlib-metadata        2.0.0                      py_1  \n",
      "intel-openmp              2020.2                      254  \n",
      "ipykernel                 5.3.4            py38h5ca1d4c_0  \n",
      "ipython                   7.19.0           py38hd4e2768_0  \n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
      "jedi                      0.18.0           py38haa95532_1  \n",
      "jpeg                      9b                   hb83a4c4_2  \n",
      "jupyter_client            6.1.7                      py_0  \n",
      "jupyter_core              4.7.0            py38haa95532_0  \n",
      "keras                     2.4.3                         0  \n",
      "keras-applications        1.0.8                      py_1  \n",
      "keras-base                2.4.3                      py_0  \n",
      "keras-preprocessing       1.1.0                      py_1  \n",
      "kiwisolver                1.3.0            py38hd77b12b_0  \n",
      "libpng                    1.6.37               h2a8f88b_0  \n",
      "libprotobuf               3.13.0.1             h200bbdf_0  \n",
      "libsodium                 1.0.18               h62dcd97_0  \n",
      "libtiff                   4.1.0                h56a325e_1  \n",
      "lz4-c                     1.9.3                h2bbff1b_0  \n",
      "markdown                  3.3.3            py38haa95532_0  \n",
      "matplotlib                3.3.2                haa95532_0  \n",
      "matplotlib-base           3.3.2            py38hba9282a_0  \n",
      "mkl                       2020.2                      256  \n",
      "mkl-service               2.3.0            py38h196d8e1_0  \n",
      "mkl_fft                   1.2.0            py38h45dec08_0  \n",
      "mkl_random                1.1.1            py38h47e9c7a_0  \n",
      "multidict                 4.7.6            py38he774522_1  \n",
      "numpy                     1.19.2           py38hadc3359_0  \n",
      "numpy-base                1.19.2           py38ha3acd2a_0  \n",
      "oauthlib                  3.1.0                      py_0  \n",
      "olefile                   0.46                       py_0  \n",
      "openssl                   1.1.1i               h2bbff1b_0  \n",
      "opt_einsum                3.1.0                      py_0  \n",
      "pandas                    1.2.1            py38hf11a4ad_0  \n",
      "parso                     0.8.1              pyhd3eb1b0_0  \n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    8.1.0            py38h4fa10fc_0  \n",
      "pip                       20.3.3           py38haa95532_0  \n",
      "prompt-toolkit            3.0.8                      py_0  \n",
      "protobuf                  3.13.0.1         py38ha925a31_1  \n",
      "pyasn1                    0.4.8                      py_0  \n",
      "pyasn1-modules            0.2.8                      py_0  \n",
      "pycparser                 2.20                       py_2  \n",
      "pygments                  2.7.4              pyhd3eb1b0_0  \n",
      "pyjwt                     2.0.1            py38haa95532_0  \n",
      "pyopenssl                 20.0.1             pyhd3eb1b0_1  \n",
      "pyparsing                 2.4.7              pyhd3eb1b0_0  \n",
      "pyqt                      5.9.2            py38ha925a31_4  \n",
      "pyreadline                2.1                      py38_1  \n",
      "pysocks                   1.7.1            py38haa95532_0  \n",
      "python                    3.8.5                h5fd99cc_1  \n",
      "python-dateutil           2.8.1              pyhd3eb1b0_0  \n",
      "pytz                      2020.5             pyhd3eb1b0_0  \n",
      "pywin32                   227              py38he774522_1  \n",
      "pyyaml                    5.4.1            py38h2bbff1b_1  \n",
      "pyzmq                     20.0.0           py38hd77b12b_1  \n",
      "qt                        5.9.7            vc14h73c81de_0  \n",
      "requests                  2.25.1             pyhd3eb1b0_0  \n",
      "requests-oauthlib         1.3.0                      py_0  \n",
      "rsa                       4.7                pyhd3eb1b0_1  \n",
      "scipy                     1.5.2            py38h14eb087_0  \n",
      "setuptools                52.0.0           py38haa95532_0  \n",
      "sip                       4.19.13          py38ha925a31_0  \n",
      "six                       1.15.0           py38haa95532_0  \n",
      "sqlite                    3.33.0               h2a8f88b_0  \n",
      "tensorboard               2.3.0              pyh4dce500_0  \n",
      "tensorboard-plugin-wit    1.6.0                      py_0  \n",
      "tensorflow                2.3.0           mkl_py38h8c0d9a2_0  \n",
      "tensorflow-base           2.3.0           eigen_py38h75a453f_0  \n",
      "tensorflow-estimator      2.3.0              pyheb71bc4_0  \n",
      "termcolor                 1.1.0                    py38_1  \n",
      "tk                        8.6.10               he774522_0  \n",
      "tornado                   6.1              py38h2bbff1b_0  \n",
      "traitlets                 5.0.5              pyhd3eb1b0_0  \n",
      "typing-extensions         3.7.4.3              hd3eb1b0_0  \n",
      "typing_extensions         3.7.4.3            pyh06a4308_0  \n",
      "urllib3                   1.26.3             pyhd3eb1b0_0  \n",
      "vc                        14.2                 h21ff451_1  \n",
      "vs2015_runtime            14.27.29016          h5e58377_2  \n",
      "wcwidth                   0.2.5                      py_0  \n",
      "werkzeug                  1.0.1              pyhd3eb1b0_0  \n",
      "wheel                     0.36.2             pyhd3eb1b0_0  \n",
      "win_inet_pton             1.1.0            py38haa95532_0  \n",
      "wincertstore              0.2                      py38_0  \n",
      "wrapt                     1.12.1           py38he774522_1  \n",
      "xz                        5.2.5                h62dcd97_0  \n",
      "yaml                      0.2.5                he774522_0  \n",
      "yarl                      1.5.1            py38he774522_0  \n",
      "zeromq                    4.3.3                ha925a31_3  \n",
      "zipp                      3.4.0              pyhd3eb1b0_0  \n",
      "zlib                      1.2.11               h62dcd97_4  \n",
      "zstd                      1.4.5                h04227a9_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/kyled/anaconda3/Scripts/jupyter\n"
     ]
    }
   ],
   "source": [
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-152745a1809a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_base)",
   "language": "python",
   "name": "ml_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
